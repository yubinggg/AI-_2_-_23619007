from google.colab import drive
drive.mount('/content/drive')

# ======================================
# 0) 기본 설정
# ======================================
import os, shutil, random, glob, hashlib, json, re
from pathlib import Path
from PIL import Image
import pandas as pd

# === 경로/옵션 설정 ===
ROOT_DRIVE = "/content/drive/MyDrive"
SRC_REAL   = f"{ROOT_DRIVE}/CelebA-HQ"                # Real 최상위 폴더(재귀 탐색)
DST        = f"{ROOT_DRIVE}/celeba_hq_binary"         # 최종 ImageFolder(root)
RESIZED_DST= f"{ROOT_DRIVE}/celeba_hq_binary_224"     
FAKES_ROOT = f"{ROOT_DRIVE}/fakes/stylegan2_celebahq" # 가짜 생성 원본 저장

NETWORK = "https://api.ngc.nvidia.com/v2/models/nvidia/research/stylegan2/versions/1/files/stylegan2-celebahq-256x256.pkl"

# ===== Multi-style 설정 =====
# fake: ψ=0.5 / 0.7 / 1.0 × noise={const, random}
STYLE_CONFIGS = [
    {"psi": 0.5, "noise": "const"},
    {"psi": 0.5, "noise": "random"},
    {"psi": 0.7, "noise": "const"},   # 기존 메인
    {"psi": 0.7, "noise": "random"},
    {"psi": 1.0, "noise": "const"},
    {"psi": 1.0, "noise": "random"},
]

# seed 분할(누수 방지) – 각 스타일 모두 이 구간으로 나눔
SEED_TRAIN = (1, 21000)
SEED_VAL   = (21001, 25500)
SEED_TEST  = (25501, 30000)

# 재현성
SEED = 42
random.seed(SEED)

def safe_rmtree(p):
    assert p.startswith("/content/drive/"), f"Refusing to delete: {p}"
    for forbid in ["/", "/content", "/content/drive", "/content/drive/MyDrive"]:
        assert p != forbid, f"Refusing to delete root-like path: {p}"
    shutil.rmtree(p, ignore_errors=True)

# 싹 지움(주의)
for p in [DST, RESIZED_DST, FAKES_ROOT]:
    safe_rmtree(p)
for sp in ["train", "val", "test"]:
    Path(f"{DST}/{sp}/real").mkdir(parents=True, exist_ok=True)
    Path(f"{DST}/{sp}/fake").mkdir(parents=True, exist_ok=True)

assert os.path.exists(SRC_REAL), f"SRC_REAL not found: {SRC_REAL}"
print("[OK] paths ready")

# ======================================
# 2) StyleGAN2-ADA 코드 받기
# ======================================
if not os.path.isdir("/content/stylegan2-ada-pytorch"):
    !git clone https://github.com/NVlabs/stylegan2-ada-pytorch.git
%cd /content/stylegan2-ada-pytorch

# ======================================
# 3) Fake 생성 (멀티 스타일)
#    각 스타일 별로 1~30000 seed 생성
# ======================================
import subprocess, shlex

def gen_range(outdir, seed_start, seed_end, trunc, noise_mode, network):
    os.makedirs(outdir, exist_ok=True)
    cmd = f"""
    python generate.py \
      --outdir="{outdir}" \
      --seeds={seed_start}-{seed_end} \
      --trunc={trunc} \
      --noise-mode={noise_mode} \
      --network="{network}"
    """
    print(cmd)
    subprocess.run(shlex.split(cmd), check=True)

# 스타일별로 폴더/태그 설정 + 이미지 생성
for cfg in STYLE_CONFIGS:
    psi = cfg["psi"]
    noise = cfg["noise"]
    tag = f"psi{psi}_noise-{noise}"   # 예: psi0.7_noise-const
    outdir = f"{FAKES_ROOT}/{tag}"
    cfg["tag"] = tag
    cfg["outdir"] = outdir
    print(f"\n[GEN] style={tag}")
    gen_range(outdir, 1, 30000, psi, noise, NETWORK)

%cd /content

# ======================================
# 4) Fake → ImageFolder로 분배(Seed 구간 + 스타일 혼합)
#    - 각 스타일에 동일한 seed range를 적용
#    - 파일명에 스타일 정보를 넣어 충돌 방지
# ======================================
def seed_from_name(name: str) -> int:
    m = re.search(r"seed(\d+)", name)
    return int(m.group(1)) if m else None

def place_file_with_rename(src_path, dst_dir, new_name):
    Path(dst_dir).mkdir(parents=True, exist_ok=True)
    dst_path = os.path.join(dst_dir, new_name)
    if not os.path.exists(dst_path):
        shutil.copy2(src_path, dst_path)
    return dst_path

valid_ext = {".jpg", ".jpeg", ".png", ".webp", ".bmp"}

fake_rows = []  # manifest용 fake 메타 정보

for cfg in STYLE_CONFIGS:
    psi = cfg["psi"]
    noise = cfg["noise"]
    tag = cfg["tag"]
    outdir = cfg["outdir"]

    fake_paths = sorted(glob.glob(f"{outdir}/seed*.png"))
    assert len(fake_paths) == 30000, f"[{tag}] expected 30000 fakes, got {len(fake_paths)}"

    print(f"[DIST] style={tag}, files={len(fake_paths)}")

    for p in fake_paths:
        fname = os.path.basename(p)
        seed = seed_from_name(fname)
        if seed is None:
            continue

        # 어떤 split에 들어갈지 결정 (seed 기준)
        if SEED_TRAIN[0] <= seed <= SEED_TRAIN[1]:
            split = "train"
        elif SEED_VAL[0] <= seed <= SEED_VAL[1]:
            split = "val"
        elif SEED_TEST[0] <= seed <= SEED_TEST[1]:
            split = "test"
        else:
            continue

        # 스타일 정보가 들어간 파일명으로 복사
        new_fname = f"{tag}_seed{seed:06d}.png"
        dst_dir = f"{DST}/{split}/fake"
        dst_path = place_file_with_rename(p, dst_dir, new_fname)

        # 해상도
        w = h = None
        try:
            with Image.open(dst_path) as im:
                w, h = im.size
        except:
            pass

        fake_rows.append({
            "split": split,
            "label": 1,
            "path": dst_path,
            "fname": new_fname,
            "seed": seed,
            "psi": psi,
            "noise": noise,
            "network": "stylegan2-celebahq-256x256.pkl",
            "variant": tag,  # 나중에 per-style 분석할 때 key로 사용
            "resolution": f"{w}x{h}" if (w and h) else ""
        })

# split별 fake 개수 확인
def count_dir_images(d):
    return len([
        f for f in glob.glob(os.path.join(d, "*"))
        if Path(f).suffix.lower() in valid_ext
    ])

n_train_fake = count_dir_images(f"{DST}/train/fake")
n_val_fake   = count_dir_images(f"{DST}/val/fake")
n_test_fake  = count_dir_images(f"{DST}/test/fake")

print("[COUNT] fake:", {
    "train": n_train_fake,
    "val":   n_val_fake,
    "test":  n_test_fake
})

# ======================================
# 5) Real → ImageFolder로 분배(수량 매칭)
#    train/val/test 각각 fake 개수와 동일 수량으로 real 구성
# ======================================
all_real = []
for root, _, files in os.walk(SRC_REAL):
    for f in files:
        if Path(f).suffix.lower() in valid_ext:
            all_real.append(os.path.join(root, f))

if not all_real:
    raise SystemExit(f"[ERR] No images found under {SRC_REAL}")

random.shuffle(all_real)

need_total   = n_train_fake + n_val_fake + n_test_fake
assert len(all_real) >= need_total, \
    f"Not enough real images: need {need_total}, have {len(all_real)}"

def copy_many_with_manifest(src_list, dst_dir, k, split, manifest_rows):
    Path(dst_dir).mkdir(parents=True, exist_ok=True)
    used = 0
    for p in src_list:
        if used >= k:
            break
        ext = Path(p).suffix.lower()
        if ext not in valid_ext:
            continue
        fname = os.path.basename(p)
        dst_path = place_file_with_rename(p, dst_dir, fname)

        w = h = None
        try:
            with Image.open(dst_path) as im:
                w, h = im.size
        except:
            pass

        manifest_rows.append({
            "split": split,
            "label": 0,
            "path": dst_path,
            "fname": fname,
            "seed": "",
            "psi": "",
            "noise": "",
            "network": "",
            "variant": "real",
            "resolution": f"{w}x{h}" if (w and h) else ""
        })
        used += 1

    # k개 사용 후 나머지 반환
    remaining = src_list[used:]
    return remaining

manifest_rows = fake_rows[:]   # fake 메타 + real 메타 같이 쓸 리스트

pool = all_real[:]
pool = copy_many_with_manifest(pool, f"{DST}/train/real", n_train_fake, "train", manifest_rows)
pool = copy_many_with_manifest(pool, f"{DST}/val/real",   n_val_fake,   "val",   manifest_rows)
pool = copy_many_with_manifest(pool, f"{DST}/test/real",  n_test_fake,  "test",  manifest_rows)

print("[COUNT] real:", {
    "train": count_dir_images(f"{DST}/train/real"),
    "val":   count_dir_images(f"{DST}/val/real"),
    "test":  count_dir_images(f"{DST}/test/real"),
})

# ======================================
# 6) Manifest 생성 (멀티 스타일)
#    컬럼: split,label(0/1),path,fname,seed,psi,noise,network,variant,resolution
# ======================================
manifest_path = f"{DST}/meta"
Path(manifest_path).mkdir(parents=True, exist_ok=True)
FINAL_MANIFEST = f"{manifest_path}/dataset_manifest_multi_style.csv"
pd.DataFrame(manifest_rows).to_csv(FINAL_MANIFEST, index=False)
print("[OK] manifest:", FINAL_MANIFEST)

# ======================================
# 7) 무결성/중복 체크
# ======================================
def md5sum(p):
    m = hashlib.md5()
    with open(p, "rb") as f:
        for chunk in iter(lambda: f.read(8192), b""):
            m.update(chunk)
    return m.hexdigest()

from collections import Counter

# 파일명 중복
names = []
for sp in ["train", "val", "test"]:
    for lb in ["real", "fake"]:
        for f in glob.glob(f"{DST}/{sp}/{lb}/*"):
            if Path(f).suffix.lower() in valid_ext:
                names.append(os.path.basename(f))

dup_names = [k for k, v in Counter(names).items() if v > 1]
print("[DUP-NAMES]", len(dup_names))

# 내용 중복(hash)
seen, dups = {}, []
for sp in ["train", "val", "test"]:
    for lb in ["real", "fake"]:
        for p in Path(f"{DST}/{sp}/{lb}").glob("*"):
            if p.suffix.lower() not in valid_ext:
                continue
            h = md5sum(str(p))
            if h in seen:
                dups.append((str(p), seen[h]))
            else:
                seen[h] = str(p)
print("[DUP-CONTENT]", len(dups))
if dups[:5]:
    print("[DUP-SAMPLE]", dups[:5])

# 요약 출력
df = pd.read_csv(FINAL_MANIFEST)
print()
print("[SUMMARY BY SPLIT/LABEL]")
print(df.groupby(["split", "label"]).size().unstack(fill_value=0))

print()
print("[SUMMARY BY SPLIT/VARIANT]")
print(df.groupby(["split", "variant"]).size().unstack(fill_value=0))
